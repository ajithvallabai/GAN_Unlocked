{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DC_GAN_notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oJrW4DAuQga"
      },
      "source": [
        "## DC-GAN \r\n",
        "\r\n",
        "- Paper - https://arxiv.org/abs/1511.06434\r\n",
        "- Abstract - In recent years, supervised learning with convolutional networks (CNNs) has seen huge adoption in computer vision applications. Comparatively, unsupervised learning with CNNs has received less attention. In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning. We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05MNI_lPuT6Y"
      },
      "source": [
        "Importing Neccesary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq_PsnGntZjZ"
      },
      "source": [
        "import argparse\r\n",
        "import os\r\n",
        "import numpy as np \r\n",
        "import math \r\n",
        "import torchvision.transforms as transforms \r\n",
        "from torchvision.utils import save_image\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import datasets\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "import torch.nn as nn \r\n",
        "import torch.nn.functional as F \r\n",
        "import torch \r\n",
        "\r\n",
        "os.makedirs(\"images\",exist_ok=True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zK2JSU7XuOt3"
      },
      "source": [
        "# constants\r\n",
        "n_epochs = 200\r\n",
        "batch_size = 64\r\n",
        "lr = 0.0002\r\n",
        "b1 = 0.5\r\n",
        "b2 = 0.999\r\n",
        "n_cpu = 8\r\n",
        "latent_dim = 100\r\n",
        "img_size = 32\r\n",
        "channels = 1\r\n",
        "sample_interval = 400\r\n",
        "img_shape = (channels, img_size, img_size)\r\n",
        "if torch.cuda.is_available():\r\n",
        "  cuda = True\r\n",
        "else:\r\n",
        "  cuda = False "
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zhj9j2a9xV8l"
      },
      "source": [
        "What is nn.Module ?\r\n",
        "\r\n",
        "- https://github.com/torch/nn/blob/master/doc/module.md\r\n",
        "\r\n",
        "- https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py\r\n",
        "\r\n",
        "What is super(Generator,self).__init__() ?\r\n",
        "\r\n",
        "- https://stackoverflow.com/a/33469090\r\n",
        "\r\n",
        "- https://stackoverflow.com/questions/576169/understanding-python-super-with-init-methods\r\n",
        "\r\n",
        "nn.linear \r\n",
        "\r\n",
        "- https://pytorch.org/docs/stable/generated/torch.nn.Linear.html\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHcSqn8mutnX"
      },
      "source": [
        "\r\n",
        "def weigths_init_normal(m):\r\n",
        "  classname = m.__class__.__name__\r\n",
        "  if classname.find(\"Conv\") != -1:\r\n",
        "    #print(\"reach\")\r\n",
        "    torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\r\n",
        "  elif classname.find(\"BatchNorm2d\") != -1:\r\n",
        "    #print(\"reach2\")\r\n",
        "    torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\r\n",
        "    torch.nn.init.constant_(m.bias.data, 0.0)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(Generator, self).__init__()\r\n",
        "    self.init_size = img_size // 4 \r\n",
        "    self.l1 = nn.Sequential(nn.Linear(latent_dim, 128*self.init_size**2 ))\r\n",
        "    #self.l1.shape\r\n",
        "    #print(self.l1.shape[0], 128, self.init_size, self.init_size)\r\n",
        "    self.conv_blocks = nn.Sequential(\r\n",
        "        nn.BatchNorm2d(128),\r\n",
        "        nn.Upsample(scale_factor=2),\r\n",
        "        nn.Conv2d(128,128,3, stride=1, padding =1),\r\n",
        "        nn.BatchNorm2d(128,0.8),\r\n",
        "        nn.LeakyReLU(0.2, inplace=True),\r\n",
        "        nn.Upsample(scale_factor=2),\r\n",
        "        nn.Conv2d(128,64,3, stride=1, padding=1),\r\n",
        "        nn.BatchNorm2d(64,0.8),\r\n",
        "        nn.LeakyReLU(0.2, inplace=True),\r\n",
        "        nn.Conv2d(64, channels, 3, stride=1, padding=1),\r\n",
        "        nn.Tanh(),\r\n",
        "    )\r\n",
        "\r\n",
        "    \r\n",
        "  def forward(self, z):\r\n",
        "    out = self.l1(z)\r\n",
        "    # reshaping the img\r\n",
        "    out = out.view(out.shape[0], 128, self.init_size, self.init_size)\r\n",
        "    print(out.shape)\r\n",
        "    img = self.conv_blocks(out)\r\n",
        "    return img \r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(Discriminator, self).__init__()\r\n",
        "    def discriminator_block(in_filters, out_filters, bn=True):\r\n",
        "      block = [nn.Conv2d(in_filters, out_filters, 3,2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\r\n",
        "      if bn:\r\n",
        "        block.append(nn.BatchNorm2d(out_filters, 0.8))\r\n",
        "      return block \r\n",
        "    self.model = nn.Sequential(\r\n",
        "        *discriminator_block(channels, 16, bn=False),\r\n",
        "        *discriminator_block(16, 32),\r\n",
        "        *discriminator_block(32, 64),\r\n",
        "        *discriminator_block(64, 128),\r\n",
        "    )\r\n",
        "    ds_size = img_size //2 ** 4\r\n",
        "    self.adv_layer = nn.Sequential(nn.Linear(128*ds_size**2, 1), nn.Sigmoid())\r\n",
        "    \r\n",
        "  def forward(self, img):\r\n",
        "    # flattening tensors\r\n",
        "    out = self.model(img)\r\n",
        "    out = out.view(out.shape[0], -1)\r\n",
        "    validity = self.adv_layer(out)\r\n",
        "    return validity\r\n",
        "\r\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uWO8Odel1Qp"
      },
      "source": [
        "# loss function\r\n",
        "adversarial_loss = torch.nn.BCELoss()\r\n",
        "\r\n",
        "# initalizing generator and discriminator\r\n",
        "generator = Generator()\r\n",
        "discriminator = Discriminator()"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8Tup8G_ut1D"
      },
      "source": [
        "\r\n",
        "\r\n",
        "if cuda:\r\n",
        "  generator.cuda()\r\n",
        "  discriminator.cuda()\r\n",
        "  adversarial_loss.cuda()\r\n",
        "\r\n",
        "generator.apply(weigths_init_normal)\r\n",
        "discriminator.apply(weigths_init_normal)\r\n",
        "\r\n",
        "# data loader\r\n",
        "os.makedirs(\"data/mnist\",exist_ok=True)\r\n",
        "dataloader = torch.utils.data.DataLoader(\r\n",
        "    datasets.MNIST(\r\n",
        "        \"data/mnist\",\r\n",
        "        train = True,\r\n",
        "        download = True,\r\n",
        "        transform = transforms.Compose( \\\r\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5],[0.5])]\r\n",
        "        ),\r\n",
        "    ),\r\n",
        "    batch_size = batch_size,\r\n",
        "    shuffle = True,\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "#optimizers\r\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1,b2))\r\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(b1,b2))\r\n",
        "\r\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYpF-Sb4jDLU"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssYbLoibjEYg"
      },
      "source": [
        "for epoch in range(n_epochs):\r\n",
        "  for i, (imgs, _) in enumerate(dataloader):\r\n",
        "    #ground truths definition\r\n",
        "    # valid \r\n",
        "    valid = Variable(Tensor(imgs.size(0),1).fill_(1.0), requires_grad=False )\r\n",
        "    # fake \r\n",
        "    fake = Variable(Tensor(imgs.size(0),1).fill_(0.0), requires_grad= False)\r\n",
        "\r\n",
        "    # Configure inuput \r\n",
        "    real_imgs = Variable(imgs.type(Tensor))\r\n",
        "\r\n",
        "    ########## Train generator ################\r\n",
        "\r\n",
        "    # clears the output of all variables from previous iteration\r\n",
        "    optimizer_G.zero_grad()\r\n",
        "\r\n",
        "    # sample noise as gen input\r\n",
        "    z = Variable(Tensor(np.random.normal(0,1,(imgs.shape[0], latent_dim))))\r\n",
        "    print(z.shape)\r\n",
        "\r\n",
        "    gen_imgs = generator(z)\r\n",
        "    # checking how much genrators image the discrimainator is able to classify as valid and then taking it as a loss and back propagating\r\n",
        "    g_loss = adversarial_loss(discriminator(gen_imgs), valid)\r\n",
        "    # backpropagation\r\n",
        "    g_loss.backward()\r\n",
        "\r\n",
        "    ######## training discriminator ###############\r\n",
        "\r\n",
        "    optimizer_D.zero_grad()\r\n",
        "\r\n",
        "    real_loss = adversarial_loss(discriminator(real_imgs), valid)\r\n",
        "\r\n",
        "    # tensor.detach() creates a tensor that shares storage with tensor that does not require grad. It detaches the output from the computational graph\r\n",
        "    # https://stackoverflow.com/questions/56816241/difference-between-detach-and-with-torch-nograd-in-pytorch#:~:text=detach()%20creates%20a%20tensor,output%20from%20the%20computational%20graph.\r\n",
        "\r\n",
        "    fake_loss = adversarial_loss(discriminator(gen_imgs.detach()),fake)\r\n",
        "    d_loss = (real_loss + fake_loss)/2 \r\n",
        "    # backpropagation\r\n",
        "    d_loss.backward()\r\n",
        "\r\n",
        "    optimizer_D.step()\r\n",
        "\r\n",
        "    print(\"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\" %\r\n",
        "          (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item()))\r\n",
        "    \r\n",
        "    batches_done = epoch * len(dataloader) + i \r\n",
        "    if batches_done % sample_interval == 0:\r\n",
        "      save_image(gen_imgs.data[25], \"images/%d.png\"%batches_done, nrow=5, normalize=True)\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "so5SYY26tkeN"
      },
      "source": [
        "### End of notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvP4s0uPsjGK"
      },
      "source": [
        "###File based code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMIimhhVohK4",
        "outputId": "969c672c-334f-4486-ef3a-f3f6da5bfdb7"
      },
      "source": [
        "%%writefile dcgan.py\r\n",
        "\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "import numpy as np\r\n",
        "import math\r\n",
        "\r\n",
        "import torchvision.transforms as transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from torchvision import datasets\r\n",
        "from torch.autograd import Variable\r\n",
        "\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch\r\n",
        "\r\n",
        "os.makedirs(\"images\", exist_ok=True)\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument(\"--n_epochs\", type=int, default=200, help=\"number of epochs of training\")\r\n",
        "parser.add_argument(\"--batch_size\", type=int, default=64, help=\"size of the batches\")\r\n",
        "parser.add_argument(\"--lr\", type=float, default=0.0002, help=\"adam: learning rate\")\r\n",
        "parser.add_argument(\"--b1\", type=float, default=0.5, help=\"adam: decay of first order momentum of gradient\")\r\n",
        "parser.add_argument(\"--b2\", type=float, default=0.999, help=\"adam: decay of first order momentum of gradient\")\r\n",
        "parser.add_argument(\"--n_cpu\", type=int, default=8, help=\"number of cpu threads to use during batch generation\")\r\n",
        "parser.add_argument(\"--latent_dim\", type=int, default=100, help=\"dimensionality of the latent space\")\r\n",
        "parser.add_argument(\"--img_size\", type=int, default=32, help=\"size of each image dimension\")\r\n",
        "parser.add_argument(\"--channels\", type=int, default=1, help=\"number of image channels\")\r\n",
        "parser.add_argument(\"--sample_interval\", type=int, default=400, help=\"interval between image sampling\")\r\n",
        "opt = parser.parse_args()\r\n",
        "print(opt)\r\n",
        "\r\n",
        "cuda = True if torch.cuda.is_available() else False\r\n",
        "\r\n",
        "\r\n",
        "def weights_init_normal(m):\r\n",
        "    classname = m.__class__.__name__\r\n",
        "    if classname.find(\"Conv\") != -1:\r\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\r\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\r\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\r\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)\r\n",
        "\r\n",
        "\r\n",
        "class Generator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Generator, self).__init__()\r\n",
        "\r\n",
        "        self.init_size = opt.img_size // 4\r\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\r\n",
        "\r\n",
        "        self.conv_blocks = nn.Sequential(\r\n",
        "            nn.BatchNorm2d(128),\r\n",
        "            nn.Upsample(scale_factor=2),\r\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\r\n",
        "            nn.BatchNorm2d(128, 0.8),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Upsample(scale_factor=2),\r\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\r\n",
        "            nn.BatchNorm2d(64, 0.8),\r\n",
        "            nn.LeakyReLU(0.2, inplace=True),\r\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\r\n",
        "            nn.Tanh(),\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, z):\r\n",
        "        out = self.l1(z)\r\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\r\n",
        "        img = self.conv_blocks(out)\r\n",
        "        return img\r\n",
        "\r\n",
        "\r\n",
        "class Discriminator(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(Discriminator, self).__init__()\r\n",
        "\r\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\r\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\r\n",
        "            if bn:\r\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\r\n",
        "            return block\r\n",
        "\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\r\n",
        "            *discriminator_block(16, 32),\r\n",
        "            *discriminator_block(32, 64),\r\n",
        "            *discriminator_block(64, 128),\r\n",
        "        )\r\n",
        "\r\n",
        "        # The height and width of downsampled image\r\n",
        "        ds_size = opt.img_size // 2 ** 4\r\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\r\n",
        "\r\n",
        "    def forward(self, img):\r\n",
        "        out = self.model(img)\r\n",
        "        out = out.view(out.shape[0], -1)\r\n",
        "        validity = self.adv_layer(out)\r\n",
        "\r\n",
        "        return validity\r\n",
        "\r\n",
        "\r\n",
        "# Loss function\r\n",
        "adversarial_loss = torch.nn.BCELoss()\r\n",
        "\r\n",
        "# Initialize generator and discriminator\r\n",
        "generator = Generator()\r\n",
        "discriminator = Discriminator()\r\n",
        "\r\n",
        "if cuda:\r\n",
        "    generator.cuda()\r\n",
        "    discriminator.cuda()\r\n",
        "    adversarial_loss.cuda()\r\n",
        "\r\n",
        "# Initialize weights\r\n",
        "generator.apply(weights_init_normal)\r\n",
        "discriminator.apply(weights_init_normal)\r\n",
        "\r\n",
        "# Configure data loader\r\n",
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\r\n",
        "dataloader = torch.utils.data.DataLoader(\r\n",
        "    datasets.MNIST(\r\n",
        "        \"../../data/mnist\",\r\n",
        "        train=True,\r\n",
        "        download=True,\r\n",
        "        transform=transforms.Compose(\r\n",
        "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\r\n",
        "        ),\r\n",
        "    ),\r\n",
        "    batch_size=opt.batch_size,\r\n",
        "    shuffle=True,\r\n",
        ")\r\n",
        "\r\n",
        "# Optimizers\r\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\r\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\r\n",
        "\r\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\r\n",
        "\r\n",
        "# ----------\r\n",
        "#  Training\r\n",
        "# ----------\r\n",
        "\r\n",
        "for epoch in range(opt.n_epochs):\r\n",
        "    for i, (imgs, _) in enumerate(dataloader):\r\n",
        "\r\n",
        "        # Adversarial ground truths\r\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\r\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\r\n",
        "\r\n",
        "        # Configure input\r\n",
        "        real_imgs = Variable(imgs.type(Tensor))\r\n",
        "\r\n",
        "        # -----------------\r\n",
        "        #  Train Generator\r\n",
        "        # -----------------\r\n",
        "\r\n",
        "        optimizer_G.zero_grad()\r\n",
        "\r\n",
        "        # Sample noise as generator input\r\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\r\n",
        "\r\n",
        "        # Generate a batch of images\r\n",
        "        gen_imgs = generator(z)\r\n",
        "\r\n",
        "        # Loss measures generator's ability to fool the discriminator\r\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\r\n",
        "\r\n",
        "        g_loss.backward()\r\n",
        "        optimizer_G.step()\r\n",
        "\r\n",
        "        # ---------------------\r\n",
        "        #  Train Discriminator\r\n",
        "        # ---------------------\r\n",
        "\r\n",
        "        optimizer_D.zero_grad()\r\n",
        "\r\n",
        "        # Measure discriminator's ability to classify real from generated samples\r\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\r\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\r\n",
        "        d_loss = (real_loss + fake_loss) / 2\r\n",
        "\r\n",
        "        d_loss.backward()\r\n",
        "        optimizer_D.step()\r\n",
        "\r\n",
        "        print(\r\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\r\n",
        "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\r\n",
        "        )\r\n",
        "\r\n",
        "        batches_done = epoch * len(dataloader) + i\r\n",
        "        if batches_done % opt.sample_interval == 0:\r\n",
        "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing decgan.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sDCFsU0VohWv",
        "outputId": "78d9008e-85f4-4ff7-fc41-928833e48f49"
      },
      "source": [
        "!python decgan.py"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Namespace(b1=0.5, b2=0.999, batch_size=64, channels=1, img_size=32, latent_dim=100, lr=0.0002, n_cpu=8, n_epochs=200, sample_interval=400)\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n",
            "9920512it [00:01, 9314936.23it/s]                 \n",
            "Extracting ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "32768it [00:00, 135006.94it/s]\n",
            "Extracting ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
            "1654784it [00:00, 2586147.76it/s]               \n",
            "Extracting ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "8192it [00:00, 47849.46it/s]\n",
            "Extracting ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "Processing...\n",
            "/usr/local/lib/python3.6/dist-packages/torchvision/datasets/mnist.py:480: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
            "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n",
            "Done!\n",
            "[Epoch 0/200] [Batch 0/938] [D loss: 0.693164] [G loss: 0.706116]\n",
            "[Epoch 0/200] [Batch 1/938] [D loss: 0.693160] [G loss: 0.705373]\n",
            "[Epoch 0/200] [Batch 2/938] [D loss: 0.693168] [G loss: 0.704654]\n",
            "[Epoch 0/200] [Batch 3/938] [D loss: 0.692946] [G loss: 0.704065]\n",
            "[Epoch 0/200] [Batch 4/938] [D loss: 0.692942] [G loss: 0.703239]\n",
            "[Epoch 0/200] [Batch 5/938] [D loss: 0.692925] [G loss: 0.702487]\n",
            "[Epoch 0/200] [Batch 6/938] [D loss: 0.692736] [G loss: 0.701870]\n",
            "[Epoch 0/200] [Batch 7/938] [D loss: 0.692601] [G loss: 0.701127]\n",
            "[Epoch 0/200] [Batch 8/938] [D loss: 0.692581] [G loss: 0.700421]\n",
            "[Epoch 0/200] [Batch 9/938] [D loss: 0.692407] [G loss: 0.699878]\n",
            "[Epoch 0/200] [Batch 10/938] [D loss: 0.692209] [G loss: 0.699248]\n",
            "[Epoch 0/200] [Batch 11/938] [D loss: 0.692143] [G loss: 0.698557]\n",
            "[Epoch 0/200] [Batch 12/938] [D loss: 0.691587] [G loss: 0.697965]\n",
            "[Epoch 0/200] [Batch 13/938] [D loss: 0.691590] [G loss: 0.696842]\n",
            "[Epoch 0/200] [Batch 14/938] [D loss: 0.691443] [G loss: 0.695746]\n",
            "[Epoch 0/200] [Batch 15/938] [D loss: 0.691251] [G loss: 0.694464]\n",
            "[Epoch 0/200] [Batch 16/938] [D loss: 0.691454] [G loss: 0.692698]\n",
            "[Epoch 0/200] [Batch 17/938] [D loss: 0.691425] [G loss: 0.690432]\n",
            "[Epoch 0/200] [Batch 18/938] [D loss: 0.691231] [G loss: 0.688638]\n",
            "[Epoch 0/200] [Batch 19/938] [D loss: 0.692165] [G loss: 0.686434]\n",
            "[Epoch 0/200] [Batch 20/938] [D loss: 0.691245] [G loss: 0.686460]\n",
            "[Epoch 0/200] [Batch 21/938] [D loss: 0.691614] [G loss: 0.684626]\n",
            "[Epoch 0/200] [Batch 22/938] [D loss: 0.691178] [G loss: 0.686016]\n",
            "[Epoch 0/200] [Batch 23/938] [D loss: 0.691995] [G loss: 0.684901]\n",
            "[Epoch 0/200] [Batch 24/938] [D loss: 0.690491] [G loss: 0.685524]\n",
            "[Epoch 0/200] [Batch 25/938] [D loss: 0.690680] [G loss: 0.686528]\n",
            "[Epoch 0/200] [Batch 26/938] [D loss: 0.690438] [G loss: 0.685196]\n",
            "[Epoch 0/200] [Batch 27/938] [D loss: 0.688617] [G loss: 0.685769]\n",
            "[Epoch 0/200] [Batch 28/938] [D loss: 0.690835] [G loss: 0.682947]\n",
            "[Epoch 0/200] [Batch 29/938] [D loss: 0.688827] [G loss: 0.687580]\n",
            "[Epoch 0/200] [Batch 30/938] [D loss: 0.690357] [G loss: 0.682302]\n",
            "[Epoch 0/200] [Batch 31/938] [D loss: 0.688144] [G loss: 0.688190]\n",
            "[Epoch 0/200] [Batch 32/938] [D loss: 0.688142] [G loss: 0.686137]\n",
            "[Epoch 0/200] [Batch 33/938] [D loss: 0.687868] [G loss: 0.685239]\n",
            "[Epoch 0/200] [Batch 34/938] [D loss: 0.683997] [G loss: 0.688628]\n",
            "[Epoch 0/200] [Batch 35/938] [D loss: 0.683352] [G loss: 0.687612]\n",
            "[Epoch 0/200] [Batch 36/938] [D loss: 0.684414] [G loss: 0.686665]\n",
            "[Epoch 0/200] [Batch 37/938] [D loss: 0.682477] [G loss: 0.688191]\n",
            "[Epoch 0/200] [Batch 38/938] [D loss: 0.681390] [G loss: 0.689221]\n",
            "[Epoch 0/200] [Batch 39/938] [D loss: 0.677879] [G loss: 0.692649]\n",
            "[Epoch 0/200] [Batch 40/938] [D loss: 0.681295] [G loss: 0.684513]\n",
            "[Epoch 0/200] [Batch 41/938] [D loss: 0.680132] [G loss: 0.676056]\n",
            "[Epoch 0/200] [Batch 42/938] [D loss: 0.680888] [G loss: 0.669759]\n",
            "[Epoch 0/200] [Batch 43/938] [D loss: 0.686096] [G loss: 0.662402]\n",
            "[Epoch 0/200] [Batch 44/938] [D loss: 0.685919] [G loss: 0.646315]\n",
            "[Epoch 0/200] [Batch 45/938] [D loss: 0.686272] [G loss: 0.646076]\n",
            "[Epoch 0/200] [Batch 46/938] [D loss: 0.679948] [G loss: 0.641622]\n",
            "[Epoch 0/200] [Batch 47/938] [D loss: 0.687432] [G loss: 0.636642]\n",
            "[Epoch 0/200] [Batch 48/938] [D loss: 0.683469] [G loss: 0.644552]\n",
            "Traceback (most recent call last):\n",
            "  File \"decgan.py\", line 170, in <module>\n",
            "    g_loss.backward()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/tensor.py\", line 221, in backward\n",
            "    torch.autograd.backward(self, gradient, retain_graph, create_graph)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\", line 132, in backward\n",
            "    allow_unreachable=True)  # allow_unreachable flag\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ysJYCADooq4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnCSmuRsoo6O"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M63JjVtAsl51"
      },
      "source": [
        "### End of Code"
      ]
    }
  ]
}